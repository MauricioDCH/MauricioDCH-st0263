{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "# Inicializamos spark\nspark", "execution_count": 2, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "<pyspark.sql.session.SparkSession object at 0x7febbe224190>", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Obtenemos el SparkContext (sc), que permite interactuar directamente con el cl\u00faster y manejar RDDs\nsc", "execution_count": 3, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "<SparkContext master=yarn appName=livy-session-0>", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos el dataframe para luego mostrar todas las tablas que tenemos en el sistema HIVE.\ndata_frame_1 = spark.sql(\"SHOW TABLES\")", "execution_count": 4, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Mostramos todas las tablas que tenemos en el sistema HIVE.\ndata_frame_1.show()", "execution_count": 5, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+---------+--------------------+-----------+\n|namespace|           tableName|isTemporary|\n+---------+--------------------+-----------+\n|  default|                docs|      false|\n|  default|               docs2|      false|\n|  default|              docss3|      false|\n|  default|                expo|      false|\n|  default|             hdiens3|      false|\n|  default|          hdiextxgui|      false|\n|  default|          hdilabhive|      false|\n|  default|      word_frequency|      false|\n|  default|    word_frequency_2|      false|\n|  default| word_frequency_ctas|      false|\n|  default|word_frequency_ct...|      false|\n|  default|wordcount_table_hive|      false|\n+---------+--------------------+-----------+", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos el dataframe para luego mostrar las 10  primeras entradas de la tabla 'hdiens3'.\ndata_frame_2 = spark.sql(\"SELECT * FROM hdiens3 LIMIT 10\")", "execution_count": 6, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Mostrar las 10 entradas de la tabla 'hdiens3'.\ndata_frame_2.show()", "execution_count": 7, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+----+-------------+-----+------+-----+-----+-----+\n|  id|      country|  hdi|lifeex|mysch|eysch|  gni|\n+----+-------------+-----+------+-----+-----+-----+\n|NULL|      country| NULL|  NULL| NULL| NULL| NULL|\n|   1|       Norway|0.943|    81|   12|   17|47557|\n|   2|    Australia|0.929|    81|   12|   18|34431|\n|   3|  Netherlands| 0.91|    80|   11|   16|36402|\n|   4|United States| 0.91|    78|   12|   16|43017|\n|   5|  New Zealand|0.908|    80|   12|   18|23737|\n|   6|       Canada|0.908|    81|   12|   16|35166|\n|   7|      Ireland|0.908|    80|   11|   18|29322|\n|   8|Liechtenstein|0.905|    79|   10|   14|83717|\n|   9|      Germany|0.905|    80|   12|   15|34854|\n+----+-------------+-----+------+-----+-----+-----+", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos el dataframe para luego mostrar todas entradas de la tabla 'hdiens3'.\ndata_frame_3 = spark.sql(\"SELECT * FROM hdiens3\")", "execution_count": 8, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Mostrar todas entradas de la tabla 'hdiens3', Nota: S\u00f3lo muestra las 20 primeras.\ndata_frame_3.show()", "execution_count": 9, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+----+--------------------+-----+------+-----+-----+-----+\n|  id|             country|  hdi|lifeex|mysch|eysch|  gni|\n+----+--------------------+-----+------+-----+-----+-----+\n|NULL|             country| NULL|  NULL| NULL| NULL| NULL|\n|   1|              Norway|0.943|    81|   12|   17|47557|\n|   2|           Australia|0.929|    81|   12|   18|34431|\n|   3|         Netherlands| 0.91|    80|   11|   16|36402|\n|   4|       United States| 0.91|    78|   12|   16|43017|\n|   5|         New Zealand|0.908|    80|   12|   18|23737|\n|   6|              Canada|0.908|    81|   12|   16|35166|\n|   7|             Ireland|0.908|    80|   11|   18|29322|\n|   8|       Liechtenstein|0.905|    79|   10|   14|83717|\n|   9|             Germany|0.905|    80|   12|   15|34854|\n|  10|              Sweden|0.904|    81|   11|   15|35837|\n|  11|         Switzerland|0.903|    82|   11|   15|39924|\n|  12|               Japan|0.901|    83|   11|   15|32295|\n|  13|Hong Kong China (...|0.898|    82|   10|   15|44805|\n|  14|             Iceland|0.898|    81|   10|   18|29354|\n|  15| Korea (Republic of)|0.897|    80|   11|   16|28230|\n|  16|             Denmark|0.895|    78|   11|   16|34347|\n|  17|              Israel|0.888|    81|   11|   15|25849|\n|  18|             Belgium|0.886|    80|   10|   16|33357|\n|  19|             Austria|0.885|    80|   10|   15|35719|\n+----+--------------------+-----+------+-----+-----+-----+\nonly showing top 20 rows", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos el dataframe para luego mostrar las 10 primeras entradas de la tabla 'expo'.\ndata_frame_4 = spark.sql(\"SELECT * FROM expo LIMIT 10\")", "execution_count": 10, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Mostrar las 10 primeras entradas de la tabla 'expo'.\ndata_frame_4.show()", "execution_count": 11, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+-------------------+---------+\n|            country|    expct|\n+-------------------+---------+\n|            country|     NULL|\n|        Afghanistan|15.487171|\n|            Albania| 29.77231|\n|            Algeria|30.830406|\n|     American Samoa|     NULL|\n|            Andorra|     NULL|\n|             Angola|56.835884|\n|Antigua and Barbuda| 44.08267|\n|          Argentina|21.706469|\n|            Armenia| 20.58361|\n+-------------------+---------+", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos el dataframe para luego mostrar todas las entradas de la tabla 'hdiens3' donde 'gni > 2000'.\ndata_frame_5 = spark.sql(\"SELECT country, gni FROM hdiens3 WHERE gni > 2000\")", "execution_count": 12, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Mostrar todas las entradas de la tabla 'hdiens3' donde 'gni > 2000', Nota: S\u00f3lo muestra las 20 primeras.\ndata_frame_5.show()", "execution_count": 13, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+--------------------+-----+\n|             country|  gni|\n+--------------------+-----+\n|              Norway|47557|\n|           Australia|34431|\n|         Netherlands|36402|\n|       United States|43017|\n|         New Zealand|23737|\n|              Canada|35166|\n|             Ireland|29322|\n|       Liechtenstein|83717|\n|             Germany|34854|\n|              Sweden|35837|\n|         Switzerland|39924|\n|               Japan|32295|\n|Hong Kong China (...|44805|\n|             Iceland|29354|\n| Korea (Republic of)|28230|\n|             Denmark|34347|\n|              Israel|25849|\n|             Belgium|33357|\n|             Austria|35719|\n|              France|30462|\n+--------------------+-----+\nonly showing top 20 rows", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos el dataframe para luego mostrar un join entre las tablas 'hdiens3' y 'expo' donde 'gni > 2000'\ndata_frame_6 = spark.sql(\"SELECT h.country, gni, expct FROM hdiens3 h JOIN expo e ON (h.country = e.country) WHERE gni > 2000\")", "execution_count": 14, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Mostrar un join entre las tablas 'hdiens3' y 'expo' donde 'gni > 2000', Nota: S\u00f3lo muestra las 20 primeras.\ndata_frame_6.show()", "execution_count": 15, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+--------------------+-----+---------+\n|             country|  gni|    expct|\n+--------------------+-----+---------+\n|             Albania| 7803| 29.77231|\n|             Algeria| 7658|30.830406|\n|             Andorra|36095|     NULL|\n|              Angola| 4874|56.835884|\n| Antigua and Barbuda|15521| 44.08267|\n|           Argentina|14527|21.706469|\n|             Armenia| 5188| 20.58361|\n|           Australia|34431|19.780243|\n|             Austria|35719|53.971355|\n|          Azerbaijan| 8666|55.125755|\n|             Bahrain|28169|     NULL|\n|            Barbados|17966| 47.34396|\n|             Belarus|13439|54.623608|\n|             Belgium|33357| 80.00875|\n|              Belize| 5812|     NULL|\n|              Bhutan| 5293|     NULL|\n|Bosnia and Herzeg...| 7664| 35.92036|\n|            Botswana|13049|32.641003|\n|              Brazil|10162| 11.15298|\n|   Brunei Darussalam|45753|     NULL|\n+--------------------+-----+---------+\nonly showing top 20 rows", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos el dataframe para luego mostrar las columnas y los tipos de datos de la tabla 'hdiens3'\ndata_frame_7 = spark.sql(\"DESCRIBE hdiens3\")", "execution_count": 16, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Mostrar las columnas y los tipos de datos de la tabla 'hdiens3'\ndata_frame_7.show()", "execution_count": 17, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+--------+---------+-------+\n|col_name|data_type|comment|\n+--------+---------+-------+\n|      id|      int|   NULL|\n| country|   string|   NULL|\n|     hdi|    float|   NULL|\n|  lifeex|      int|   NULL|\n|   mysch|      int|   NULL|\n|   eysch|      int|   NULL|\n|     gni|      int|   NULL|\n+--------+---------+-------+", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos la tabla docs3\nspark.sql(\"\"\"\n    CREATE EXTERNAL TABLE IF NOT EXISTS docs3 (line STRING)\n    STORED AS TEXTFILE\n    LOCATION 's3://datasets-mauricio/datasets/gutenberg-small'\n\"\"\")", "execution_count": 18, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "DataFrame[]", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos el dataframe para luego mostrar todas las tablas NUEVAMENTE que tenemos en el sistema HIVE, \n# verificando la creaci\u00f3n de la tabla docs3.\ndata_frame_8 = spark.sql(\"SHOW TABLES\")", "execution_count": 19, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Mostrar todas las tablas NUEVAMENTE que tenemos en el sistema HIVE, \n# verificando la creaci\u00f3n de la tabla docs3.\ndata_frame_8.show()", "execution_count": 20, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+---------+--------------------+-----------+\n|namespace|           tableName|isTemporary|\n+---------+--------------------+-----------+\n|  default|                docs|      false|\n|  default|               docs2|      false|\n|  default|               docs3|      false|\n|  default|              docss3|      false|\n|  default|                expo|      false|\n|  default|             hdiens3|      false|\n|  default|          hdiextxgui|      false|\n|  default|          hdilabhive|      false|\n|  default|      word_frequency|      false|\n|  default|    word_frequency_2|      false|\n|  default| word_frequency_ctas|      false|\n|  default|word_frequency_ct...|      false|\n|  default|wordcount_table_hive|      false|\n+---------+--------------------+-----------+", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos el dataframe para luego mostrar el resultado de la creaci\u00f3n de la query a la tabla llamada 'docs3'\ndata_frame_9 = spark.sql(\"SELECT * FROM docs3\")", "execution_count": 21, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Mostrar el resultado de la creaci\u00f3n de la query a la tabla llamada 'docs3', Nota: S\u00f3lo muestra las 20 primeras.\ndata_frame_9.show()", "execution_count": 22, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+--------------------+\n|                line|\n+--------------------+\n|                    |\n|     LINCOLN LETTERS|\n|                    |\n|  By Abraham Lincoln|\n|                    |\n|                    |\n|Published by The ...|\n|                    |\n|                    |\n|                    |\n|                    |\n|                NOTE|\n|                    |\n|The letters herei...|\n|the man, and are ...|\n|it requires no co...|\n|appreciate them. ...|\n|admonitions in th...|\n|the same sheet wi...|\n|                    |\n+--------------------+\nonly showing top 20 rows", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos el dataframe para luego mostrar el resultado de ordenar por palabra y traer m\u00e1ximo 10 palabras de manera descendente\ndata_frame_10 = spark.sql(\"\"\"\n    SELECT word, count(1) AS count FROM (SELECT explode(split(line,' ')) AS word FROM docs3) w \n    GROUP BY word \n    ORDER BY word DESC LIMIT 10;\n\"\"\")", "execution_count": 23, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Mostrar el resultado de ordenar por palabra y traer m\u00e1ximo 10 palabras de manera descendente\ndata_frame_10.show()", "execution_count": 24, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+---------+-----+\n|     word|count|\n+---------+-----+\n|\u00c6schines,|    1|\n|   zigzag|    1|\n|     zest|    1|\n|   zenith|    1|\n|zealously|    1|\n| zealous,|    1|\n|  zealous|    5|\n|    zeal,|    3|\n|     zeal|    8|\n| youthful|    2|\n+---------+-----+", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos el dataframe para luego mostrar ordenar por palabra y traer todas las palabras de manera descendente\ndata_frame_11 = spark.sql(\"\"\"\n    SELECT word, count(1) AS count FROM (SELECT explode(split(line,' ')) AS word FROM docs3) w \n    GROUP BY word \n    ORDER BY word DESC;\n\"\"\")", "execution_count": 27, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Mostrar ordenar por palabra y traer todas las palabras de manera descendente, Nota: S\u00f3lo muestra las 20 primeras.\ndata_frame_11.show()", "execution_count": 28, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+------------+-----+\n|        word|count|\n+------------+-----+\n|   \u00c6schines,|    1|\n|      zigzag|    1|\n|        zest|    1|\n|      zenith|    1|\n|   zealously|    1|\n|    zealous,|    1|\n|     zealous|    5|\n|       zeal,|    3|\n|        zeal|    8|\n|    youthful|    2|\n|      youth;|    1|\n|      youth.|    1|\n|      youth,|    5|\n|     youth's|    1|\n|       youth|    8|\n| yourselves?|    8|\n|yourselves.\"|    1|\n| yourselves.|   16|\n| yourselves,|   14|\n|  yourselves|   32|\n+------------+-----+\nonly showing top 20 rows", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos el dataframe para luego mostrar ordenado por frecuencia de menor a mayor y traer m\u00e1ximo 10 palabras de manera descendente.\ndata_frame_12 = spark.sql(\"\"\"\n    SELECT word, count(1) AS count FROM (SELECT explode(split(line,' ')) AS word FROM docs3) w \n    GROUP BY word \n    ORDER BY count DESC LIMIT 10;\n\"\"\")", "execution_count": 29, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Mostrar ordenado por frecuencia de menor a mayor y traer m\u00e1ximo 10 palabras de manera descendente.\ndata_frame_12.show()", "execution_count": 30, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+----+-----+\n|word|count|\n+----+-----+\n| the|44647|\n|  of|28020|\n|    |27298|\n|  to|23208|\n| and|20444|\n|  in|13174|\n|that|12265|\n|   I|10880|\n|   a|10431|\n|  is| 7776|\n+----+-----+", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos el dataframe para luego mostrar ordenado por frecuencia de menor a mayor y traer todas las palabras de manera descendente.\ndata_frame_13 = spark.sql(\"\"\"\n    SELECT word, count(1) AS count FROM (SELECT explode(split(line,' ')) AS word FROM docs3) w \n    GROUP BY word \n    ORDER BY count DESC;\n\"\"\")", "execution_count": 31, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Mostrar ordenado por frecuencia de menor a mayor y traer todas las palabras de manera descendente.\n# Nota: S\u00f3lo muestra las 20 primeras.\ndata_frame_13.show()", "execution_count": 32, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+----+-----+\n|word|count|\n+----+-----+\n| the|44647|\n|  of|28020|\n|    |27298|\n|  to|23208|\n| and|20444|\n|  in|13174|\n|that|12265|\n|   I|10880|\n|   a|10431|\n|  is| 7776|\n|  be| 7148|\n|  it| 6899|\n|  as| 6473|\n| not| 5920|\n| for| 5658|\n|have| 5060|\n|  by| 4571|\n| you| 4328|\n|  he| 4111|\n| was| 4029|\n+----+-----+\nonly showing top 20 rows", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos el dataframe para luego mostrar ordenado por frecuencia de mayor a menor y traer todas las palabras de manera ascendente.\ndata_frame_14 = spark.sql(\"\"\"\n    SELECT word, count(1) AS count FROM (SELECT explode(split(line,' ')) AS word FROM docs3) w \n    GROUP BY word \n    ORDER BY count ASC;\n\"\"\")", "execution_count": 33, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true, "scrolled": true}, "cell_type": "code", "source": "# Mostrar ordenado por frecuencia de mayor a menor y traer todas las palabras de manera ascendente.\n# Nota: S\u00f3lo muestra las 20 primeras.\ndata_frame_14.show()", "execution_count": 35, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+-------------+-----+\n|         word|count|\n+-------------+-----+\n|   prejudice.|    1|\n|   \"Resolved:|    1|\n|       adroit|    1|\n|     LONGMANS|    1|\n|     Resolves|    1|\n|      cause--|    1|\n|   (Houghton,|    1|\n|           07|    1|\n|       _more_|    1|\n|DELIBERATELY,|    1|\n| Congressman,|    1|\n|   COLLECTION|    1|\n|      Hapgood|    1|\n|REVOLUTIONARY|    1|\n|     patches.|    1|\n|      _lazy_,|    1|\n|       fail_.|    1|\n|       WRONG,|    1|\n|        1822.|    1|\n|         WELL|    1|\n+-------------+-----+\nonly showing top 20 rows", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# RETO\n# OPCI\u00d3N 1.\n# En la cosola, ejecutamos el siguiente comando para crer un nuevo directorio en el bucket 'datasets-mauricio'\n# Para luego crear una tabla all\u00ed.\n# Comando: hadoop fs -mkdir s3a://datasets-mauricio/reto-lab-sparksql/\n\n# Crear la tabla 'word_frequency_3' y especificar la ruta en S3 's3a://datasets-mauricio/reto-lab-sparksql/word_frequency_3'\nspark.sql(\"\"\"\n    CREATE TABLE IF NOT EXISTS word_frequency_3 (\n        word STRING,\n        count INT\n    )\n    USING parquet\n    LOCATION 's3a://datasets-mauricio/reto-lab-sparksql/word_frequency_3'\n\"\"\")", "execution_count": 40, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "DataFrame[]", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos el dataframe para luego mostrar todas las tablas NUEVAMENTE que tenemos en el sistema HIVE, \n# verificando la creaci\u00f3n de la tabla word_frequency_3.\ndata_frame_15 = spark.sql(\"SHOW TABLES\")", "execution_count": 41, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Mostrar todas las tablas NUEVAMENTE que tenemos en el sistema HIVE, \n# verificando la creaci\u00f3n de la tabla word_frequency_3.\ndata_frame_15.show()", "execution_count": 42, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+---------+--------------------+-----------+\n|namespace|           tableName|isTemporary|\n+---------+--------------------+-----------+\n|  default|                docs|      false|\n|  default|               docs2|      false|\n|  default|               docs3|      false|\n|  default|              docss3|      false|\n|  default|                expo|      false|\n|  default|             hdiens3|      false|\n|  default|          hdiextxgui|      false|\n|  default|          hdilabhive|      false|\n|  default|      word_frequency|      false|\n|  default|    word_frequency_2|      false|\n|  default|    word_frequency_3|      false|\n|  default| word_frequency_ctas|      false|\n|  default|word_frequency_ct...|      false|\n|  default|wordcount_table_hive|      false|\n+---------+--------------------+-----------+", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos el dataframe para luego mostrar que la tabla est\u00e9 vac\u00eda\ndata_frame_16 = spark.sql(\"SELECT * FROM word_frequency_3;\")", "execution_count": 43, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Mostrar que la tabla est\u00e9 vac\u00eda\ndata_frame_16.show()", "execution_count": 44, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+----+-----+\n|word|count|\n+----+-----+\n+----+-----+", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Llenar la tabla con los resultados del query\nspark.sql(\"\"\"\n    INSERT INTO word_frequency_3\n    SELECT word, count(1) AS count \n    FROM (\n        SELECT explode(split(line,' ')) AS word \n        FROM docs3\n    ) w \n    GROUP BY word \n    ORDER BY count DESC;\n\"\"\")", "execution_count": 45, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "DataFrame[]", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos el dataframe para luego mostrar la creaci\u00f3n del contenido de la tabla.\ndata_frame_17 = spark.sql(\"SELECT * FROM word_frequency_3;\")", "execution_count": 46, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Mostrar la creaci\u00f3n del contenido de la tabla.\n# Nota: S\u00f3lo muestra las 20 primeras.\ndata_frame_17.show()", "execution_count": 47, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+----+-----+\n|word|count|\n+----+-----+\n| the|44647|\n|  of|28020|\n|    |27298|\n|  to|23208|\n| and|20444|\n|  in|13174|\n|that|12265|\n|   I|10880|\n|   a|10431|\n|  is| 7776|\n|  be| 7148|\n|  it| 6899|\n|  as| 6473|\n| not| 5920|\n| for| 5658|\n|have| 5060|\n|  by| 4571|\n| you| 4328|\n|  he| 4111|\n| was| 4029|\n+----+-----+\nonly showing top 20 rows", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# OPCI\u00d3N 2.\n# Crear la tabla 'word_frequency_ctas_3' y especificar la ruta en S3 's3a://datasets-mauricio/reto-lab-sparksql/word_frequency_ctas_3'\nspark.sql(\"\"\"\n    CREATE TABLE word_frequency_ctas_3\n    USING parquet\n    LOCATION 's3a://datasets-mauricio/reto-lab-sparksql/word_frequency_ctas_3'\n    AS\n    SELECT word, count(1) AS count\n    FROM (\n        SELECT explode(split(line, ' ')) AS word\n        FROM docs3\n    ) w\n    GROUP BY word\n    ORDER BY count DESC\n\"\"\")\n", "execution_count": 48, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "DataFrame[]", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Creamos el dataframe para luego mostrar la creaci\u00f3n del contenido de la tabla.\ndata_frame_18 = spark.sql(\"SELECT * FROM word_frequency_ctas_3;\")", "execution_count": 49, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Mostrar la creaci\u00f3n del contenido de la tabla.\n# Nota: S\u00f3lo muestra las 20 primeras.\ndata_frame_18.show()", "execution_count": 50, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+----+-----+\n|word|count|\n+----+-----+\n| the|44647|\n|  of|28020|\n|    |27298|\n|  to|23208|\n| and|20444|\n|  in|13174|\n|that|12265|\n|   I|10880|\n|   a|10431|\n|  is| 7776|\n|  be| 7148|\n|  it| 6899|\n|  as| 6473|\n| not| 5920|\n| for| 5658|\n|have| 5060|\n|  by| 4571|\n| you| 4328|\n|  he| 4111|\n| was| 4029|\n+----+-----+\nonly showing top 20 rows", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# Mostrar la creaci\u00f3n del contenido de m\u00e1ximo 5 entradas la tabla.\ndata_frame_18.show(5)", "execution_count": 51, "outputs": [{"output_type": "display_data", "data": {"text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),\u2026", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": ""}}, "metadata": {}}, {"output_type": "stream", "text": "+----+-----+\n|word|count|\n+----+-----+\n| the|44647|\n|  of|28020|\n|    |27298|\n|  to|23208|\n| and|20444|\n+----+-----+\nonly showing top 5 rows", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": "python"}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 3}, "file_extension": ".py", "pygments_lexer": "python3"}}, "nbformat": 4, "nbformat_minor": 5}