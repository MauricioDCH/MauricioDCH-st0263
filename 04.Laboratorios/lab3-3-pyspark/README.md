# LABORATORIO 3-3 - SPARK CON NOTEBOOKS Y PYSPARK.

---
---
---

# CONTENIDO DEL EJERCICIO SOLICITADO.
## ST0263 TÓPICOS ESPECIALES EN TELEMÁTICA, 2024-2
### Lab 3-3 - Spark con Notebooks y PySpark.

* Realizar la parte 1, está en: [Parte 1.](part-1/contenido-parte-1.md)
* Realice la reproducción y entendimiento de los notebooks que hay en: [Parte 2.](part-2/contenido-parte-2.md)

---
---
---

## PySpark

### Breve descripción.

**PySpark** es la interfaz de Python para **Apache Spark**, una plataforma de procesamiento de datos distribuidos que permite el análisis y procesamiento de grandes volúmenes de datos en clusters. PySpark aprovecha las capacidades de Spark para realizar procesamiento de datos en memoria de manera rápida y eficiente, lo que lo convierte en una herramienta popular para realizar análisis de Big Data.

**Características principales de PySpark:**
1. **Procesamiento Distribuido**: PySpark permite procesar datos distribuidos a través de un cluster utilizando RDDs (Resilient Distributed Datasets) y DataFrames, lo que proporciona una gran flexibilidad y escalabilidad en el manejo de datos.
2. **Interfaz de Python**: A través de PySpark, los usuarios pueden escribir trabajos de procesamiento de datos utilizando Python, lo que facilita su adopción entre los usuarios que ya están familiarizados con este lenguaje.
3. **Operaciones en Memoria**: PySpark optimiza el procesamiento de datos al realizar operaciones en memoria, lo que reduce considerablemente el tiempo de procesamiento en comparación con los sistemas basados en disco, como Hadoop.
4. **Soporte para Machine Learning**: PySpark incluye una biblioteca de **MLlib** para el aprendizaje automático, que permite construir modelos de Machine Learning a gran escala, así como una biblioteca de **GraphX** para procesamiento de grafos.

**Casos de uso**:
PySpark es adecuado para **procesamiento en tiempo real** y análisis de grandes volúmenes de datos tanto estructurados como no estructurados. Se utiliza frecuentemente en aplicaciones de análisis de logs, procesamiento de datos en tiempo real (streaming), análisis de datos financieros, y en tareas de **Machine Learning** a gran escala.

### Las guías de solución para el sistema PySpark están en el repositorio en los siguientes links.

- ## [Guía de PySpark - Parte 1.](part-1/guia-pyspark-parte-1.md)
- ## [Guía de PySpark - Parte 2.](part-2/guia-pyspark-parte-2.md)